
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>:HIPSTER_DEV_BLOG</title>
  <meta name="author" content="Tim B.">

  
  <meta name="description" content="ZeroC Ice is a distributed computing platform supporting many languages including Java. Building
an Ice project requires compiling &ldquo;slice&rdquo &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://hipsterdevblog.com">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title=":HIPSTER_DEV_BLOG" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Fjalla+One' rel='stylesheet' type='text/css'>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-52141399-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">:HIPSTER_DEV_BLOG</a></h1>
  
    <h2>Another Octopress blog about programming and infrastructure.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:hipsterdevblog.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/04/21/building-zeroc-ice-projects-with-gradle-and-intellij/">Building ZeroC Ice 3.5 Projects With Gradle and IntelliJ</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-04-21T19:35:35+10:00" pubdate data-updated="true">Apr 21<sup>st</sup>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="https://zeroc.com/">ZeroC Ice</a> is a distributed computing platform supporting many languages including Java. Building
an Ice project requires compiling &ldquo;slice&rdquo; data structure definitions into a compatible Java interface. Most often
it is recommended to use the <a href="https://zeroc.com/eclipse.html">Eclipse plugin</a>, however I prefer to use IntelliJ and
a build tool which is IDE agnostic. Official Gradle support <a href="https://doc.zeroc.com/display/Ice36/Gradle+Slice+Plug-in">is coming</a>
 in Ice 3.6, but that&rsquo;s still in beta. Fortunately it&rsquo;s quite easy to invoke te slice2java tool from Gradle and
 develop Ice 3.5 projects on Gradle and IntelliJ by extension.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/04/21/building-zeroc-ice-projects-with-gradle-and-intellij/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/03/01/part-2-exporting-and-analysing-cloudwatch-logs-with-data-pipeline-and-emr/">Part 2: Exporting and Analysing CloudWatch Logs With Data Pipeline and EMR</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-03-01T16:54:54+10:00" pubdate data-updated="true">Mar 1<sup>st</sup>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>If you followed <a href="/blog/2015/03/01/part-2-exporting-and-analysing-cloudwatch-logs-with-data-pipeline-and-emr/">Part 1</a>
you&rsquo;ll now have your CloudWatch logs sitting conveniently in S3 to be analysed. You could now download them
and search each file individually using grep or a similar tool, but it would be much nicer to be able to search
by field and construct complex queries with multiple conditions.</p>

<p>Thankfully you have <a href="http://aws.amazon.com/elasticmapreduce/">Elastic Map Reduce</a> (EMR) at your disposal, which can
help you analyse your logs straight from S3 using a nice UI (Hue) and with an SQL-like query language you&rsquo;re already
familiar with (Hive). EMR is typically employed to process terabytes of data, but it works well on relatively small
data-sets too and will easily scale up if you happen to have a huge amount of logs to process. Running an on-demand
EMR cluster for 6 hours also only costs less than $2.</p>

<p>This blog post will cover setting up an EMR cluster, logging into Hue, then using Hive to format and query the Apache
HTTP access logs exported from CloudWatch in Part 1.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/03/01/part-2-exporting-and-analysing-cloudwatch-logs-with-data-pipeline-and-emr/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/02/24/part-1-exporting-and-analysing-cloudwatch-logs-with-data-pipeline-and-emr/">Part 1: Exporting and Analysing CloudWatch Logs With Data Pipeline and EMR</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-02-24T19:47:52+10:00" pubdate data-updated="true">Feb 24<sup>th</sup>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>You&rsquo;ve just discovered one of your instances has been <em>hacked</em>! A new instance is being launched to replace it,
 but you have no idea how the attacker got access in the first place and you need to stop it happening again. The clues
 are hidden somewhere in your HTTP access logs which are conveniently sitting in CloudWatch logs. Unfortunately accessing
 and analysing those logs from CloudWatch isn&rsquo;t as simple as you thought. The only refinement available is by ingestion
 time and there&rsquo;s no way you can trawl through days of logs by hand. You&rsquo;ll need to analyse the logs externally
 but that&rsquo;s a challenge too - there&rsquo;s no automated export to S3 and the GetLogEvents API action is limited to pages of 1MB
 and 10 requests per second. Once you get the logs out you have to figure out how to analyse them, what you&rsquo;re looking for
 is too complex for simple text searches and loading tens of GB of logs into an RDBMS would be tedious.</p>

<p>Fortunately you found this blog post! <a href="http://aws.amazon.com/elasticmapreduce/">Elastic Map Reduce (EMR)</a> allows you to
quickly and conveniently create a Hadoop cluster running Hive. It might seem like overkill to use Hadoop to process
just a few GB of logs once-off, but Hive provides a convenient SQL-like interface and works perfectly fine at small scale.
Plus, considering you pay by the hour the cost is almost negligible.</p>

<p>The only question is how to get your logs out of CloudWatch and into S3 for EMR to process, so I recently wrote a small
tool called <a href="https://github.com/Tim-B/cwlogs-s3">cwlogs-s3</a> to help with this process. Part 1 of this blog post will
cover how to export your logs to S3 using cwlogs-s3 and Data Pipeline, then Part 2 will cover how to analyse those
logs with Hive on EMR.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/02/24/part-1-exporting-and-analysing-cloudwatch-logs-with-data-pipeline-and-emr/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/01/23/automated-haproxy-failover-on-opsworks/">Automated HAProxy Failover on OpsWorks</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-01-23T11:27:10+10:00" pubdate data-updated="true">Jan 23<sup>rd</sup>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Without a doubt ELB is the simplest load balancing solution on AWS, however it may not be suitable for all users
 given it doesn&rsquo;t support features such as a static IP. Fortunately OpsWorks makes it only marginally more complicated
 to <a href="http://docs.aws.amazon.com/opsworks/latest/userguide/workinglayers-load.html">set up HAProxy</a> as an alternative.</p>

<p>The AWS ecosystem encourages you to implement redundancy across availability zones and to avoid a single point of
failure (SPOF). HAProxy will give you many additional features over ELB, however it is difficult to achieve cross-zone redundancy
 and automated failover as supported natively by ELB. DNS round-robbin can help balance load across multiple HAProxy instances
 to achieve scalability, however this solution does not help to achieve high availability.</p>

<p>This blog post will demonstrate how to implement automated failover using a self-monitoring pair of HAProxy instances in an
 active/standby configuration. When a failure is detected the healthy standby will automatically take control of the
 elastic IP (EIP) assigned to the pair and ensure the service can continue to function. A notification will also be triggered
 via SNS to alert you that a failover has taken place.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/01/23/automated-haproxy-failover-on-opsworks/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/01/03/revisited-retrieving-files-from-s3-using-chef-on-opsworks/">Revisited: Retrieving Files From S3 Using Chef on OpsWorks</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-01-03T09:13:42+10:00" pubdate data-updated="true">Jan 3<sup>rd</sup>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>One of my earliest and most popular posts is <a href="/blog/2014/06/22/retrieving-files-from-s3-using-chef-on-opsworks/">Retrieving Files From S3 Using Chef on OpsWorks</a>.
 That posts uses the <a href="https://github.com/opscode-cookbooks/aws">Opscode AWS cookbook</a> which in turn uses the <a href="https://github.com/rightscale/right_aws">right_aws</a>
 gem. While this method is fine - particularly if you&rsquo;re not using OpsWorks - there are some situations where it&rsquo;s not ideal.</p>

<p>Recently I&rsquo;ve started using the aws-sdk gem directly which is bundled with the OpsWorks agent. The version at the time of
 writing is 1.53.0.</p>

<p>The advantages of this are:</p>

<ul>
<li>Support for <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html">IAM instance roles</a>,
meaning you don&rsquo;t have to pass AWS credentials via your custom JSON.</li>
<li>No dependencies on external cookbooks.</li>
<li>Will ordinarily be run at the compile stage, therefore you could download a JSON file, parse it, then use it to
generate resources if you wanted.</li>
</ul>


<p>The disadvantages are:</p>

<ul>
<li>It&rsquo;s not entirely clear, but my feeling is that the gems included with the OpsWorks agent aren&rsquo;t necessarily
part of the API &ldquo;contract&rdquo; provided by OpsWorks for cookbook developers. Therefore there is no guarantee that AWS
won&rsquo;t change the version or even remove it entirely without notice. I think it&rsquo;s unlikely that they&rsquo;ll remove the
aws-sdk gem or move to a version with compatibility breaking changes any time soon, but it&rsquo;s possible.</li>
<li>Less &ldquo;chef-like&rdquo; solution, although you could write your own chef resource to wrap it</li>
<li>If you&rsquo;re not using OpsWorks then the aws-sdk will create another dependency</li>
</ul>


<p>This blog post provides an example of how to use the bundled aws-sdk gem to download a file from S3 using IAM instance
 roles on OpsWorks.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/01/03/revisited-retrieving-files-from-s3-using-chef-on-opsworks/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/01/01/my-2015-aws-wish-list/">My 2015 AWS Wish List</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-01-01T22:53:23+10:00" pubdate data-updated="true">Jan 1<sup>st</sup>, 2015</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>As a new year dawns it occurred to me how much AWS functionality I now use heavily wasn&rsquo;t available only a year ago.
 Almost every day I check the <a href="http://aws.amazon.com/blogs/aws/">AWS blog</a> to find some new feature is available. This
 got me thinking about the functionality I&rsquo;d like to see in 2015, so I put together a list of my top 5.</p>

<p>I&rsquo;m sure the engineers at AWS are already working on some (if not most) of these, but if not then hopefully someone sees
 this post and gets a great idea!</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2015/01/01/my-2015-aws-wish-list/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/12/21/monitoring-per-application-metrics-with-cloudwatch-logs-and-opsworks/">Monitoring Per Application Metrics With CloudWatch Logs and OpsWorks</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-12-21T10:53:24+10:00" pubdate data-updated="true">Dec 21<sup>st</sup>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://aws.amazon.com/about-aws/whats-new/2014/07/10/introducing-amazon-cloudwatch-logs/">CloudWatch logs</a> is a cheap and
 easy to set up centralised logging solution. At the moment it lacks several valuable features such as a convenient way
 to search logs, however it does an <em>excellent</em> job at providing graphing and alerting on aggregated metrics pulled from
 ingested log data. An obvious application for this is to monitor HTTP server statistics to provide graphs of overall
 request rates, response sizes, and error rates.</p>

<p><a href="http://aws.amazon.com/opsworks/">OpsWorks</a> makes it easy to orchestrate a fleet of EC2 instances serving multiple applications
 (as oppose to <a href="http://aws.amazon.com/elasticbeanstalk/">Elastic Beanstalk</a> which only hosts a single application). Apache is
 the default HTTP server for most OpsWorks layer types.</p>

<p>This post demonstrates how to setup CloudWatch logs for Apache access logs on OpsWorks, then create custom CloudWatch
 metrics for an individual OpsWorks application to graph the HTTP request rate.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/12/21/monitoring-per-application-metrics-with-cloudwatch-logs-and-opsworks/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/12/19/how-far-can-you-go-with-haproxy-and-a-t2-dot-micro/">How Far Can You Go With HAProxy and a t2.micro</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-12-19T09:56:13+10:00" pubdate data-updated="true">Dec 19<sup>th</sup>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Load balancing is critical to any scalable and highly available cloud application. The obvious choice for load balancing
 on AWS is <a href="http://aws.amazon.com/elasticloadbalancing/">ELB</a>, but unfortunately if you require features such as a static
 IP or URL based request routing then ELB isn&rsquo;t an option.</p>

<p><a href="http://www.haproxy.org/">HAProxy</a> is a great solution that performs extremely well even on small EC2 instance types. It
 is also a supported layer type in <a href="http://docs.aws.amazon.com/opsworks/latest/userguide/workinglayers-load.html">OpsWorks</a>
 which makes it the obvious choice for OpsWorks users.</p>

<p>It&rsquo;s well known that several large application servers can be served by just a single small HAProxy server, but what is
the definition of small? How about the smallest EC2 instance on offer - the <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/t2-instances.html">t2.micro</a>?
 This blog post puts HAProxy on a t2.micro to the test using <a href="https://loader.io/">loader.io</a> to determine just how many requests/second it
 can handle and whether CPU or network is the limiting factor.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/12/19/how-far-can-you-go-with-haproxy-and-a-t2-dot-micro/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/12/07/writing-functions-for-aws-lambda-using-npm-and-grunt/">Writing Functions for AWS Lambda Using NPM and Grunt</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-12-07T11:51:16+10:00" pubdate data-updated="true">Dec 7<sup>th</sup>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>AWS <a href="http://aws.amazon.com/blogs/aws/run-code-cloud/">recently announced</a> a new compute product called <a href="http://aws.amazon.com/lambda/">Lambda</a>
 allowing users to run Node.js functions on full managed infrastructure while paying only for the actual compute time
 used.</p>

<p><a href="https://www.npmjs.org/">NPM</a> is the primary package manager for Node.js, and while Lambda does not provide explicit
 NPM support it is possible to bundle NPM packages with your function to leverage 3rd party modules.</p>

<p><a href="http://gruntjs.com/">Grunt</a> is a task runner for JavaScript, allowing easy automation of project tasks such as building
 and packaging. Recently I <a href="https://github.com/Tim-B/grunt-aws-lambda">released a Grunt plugin</a> to assist in testing Lambda
 functions and packaging functions including NPM dependencies.</p>

<p>This blog post provides an example of how to use NPM, Grunt and the grunt-aws-lambda plugin to create a Lambda function
 which will scrape a web page and save a list of links within that page to S3 using the cheerio NPM package.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/12/07/writing-functions-for-aws-lambda-using-npm-and-grunt/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/11/25/part-3-integrating-opsworks-and-codedeploy/">Part 3: Integrating OpsWorks and CodeDeploy</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-11-25T11:43:36+10:00" pubdate data-updated="true">Nov 25<sup>th</sup>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>This is part 3 of <a href="/blog/categories/integrating-opsworks-and-codedeploy/">integrating OpsWorks and CodeDeploy</a>.</p>

<p>This section covers creating the CodeDeploy deployment, deploying it to the configured OpsWorks stack and demonstrating the results of the integration.
 <a href="/blog/2014/11/23/integrating-opsworks-and-codedeploy/">Click here</a> for Part 1.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/11/25/part-3-integrating-opsworks-and-codedeploy/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/2">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/04/21/building-zeroc-ice-projects-with-gradle-and-intellij/">Building ZeroC Ice 3.5 Projects With Gradle and IntelliJ</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/01/part-2-exporting-and-analysing-cloudwatch-logs-with-data-pipeline-and-emr/">Part 2: Exporting and Analysing CloudWatch Logs With Data Pipeline and EMR</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/24/part-1-exporting-and-analysing-cloudwatch-logs-with-data-pipeline-and-emr/">Part 1: Exporting and Analysing CloudWatch Logs With Data Pipeline and EMR</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/01/23/automated-haproxy-failover-on-opsworks/">Automated HAProxy Failover on OpsWorks</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/01/03/revisited-retrieving-files-from-s3-using-chef-on-opsworks/">Revisited: Retrieving Files From S3 Using Chef on OpsWorks</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015.
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> and
    <a href="https://github.com/vladigleba/readify">Readify</a></span>.
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'hipsterdevblog';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
